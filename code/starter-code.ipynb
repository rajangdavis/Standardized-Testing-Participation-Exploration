{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data and perform basic operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Load the data in using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "act_data = pd.read_csv(\"../data/act.csv\")\n",
    "sat_data = pd.read_csv(\"../data/sat.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Print the first ten rows of each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>National</td>\n",
       "      <td>60%</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>65%</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>62%</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>California</td>\n",
       "      <td>31%</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>100%</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>31%</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>18%</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>32%</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 State Participation  English  Math  Reading  \\\n",
       "0           0              National           60%     20.3  20.7     21.4   \n",
       "1           1               Alabama          100%     18.9  18.4     19.7   \n",
       "2           2                Alaska           65%     18.7  19.8     20.4   \n",
       "3           3               Arizona           62%     18.6  19.8     20.1   \n",
       "4           4              Arkansas          100%     18.9  19.0     19.7   \n",
       "5           5            California           31%     22.5  22.7     23.1   \n",
       "6           6              Colorado          100%     20.1  20.3     21.2   \n",
       "7           7           Connecticut           31%     25.5  24.6     25.6   \n",
       "8           8              Delaware           18%     24.1  23.4     24.8   \n",
       "9           9  District of Columbia           32%     24.4  23.5     24.9   \n",
       "\n",
       "   Science  Composite  \n",
       "0     21.0       21.0  \n",
       "1     19.4       19.2  \n",
       "2     19.9       19.8  \n",
       "3     19.8       19.7  \n",
       "4     19.5       19.4  \n",
       "5     22.2       22.8  \n",
       "6     20.9       20.8  \n",
       "7     24.6       25.2  \n",
       "8     23.6       24.1  \n",
       "9     23.5       24.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>5%</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>38%</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>30%</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3%</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>California</td>\n",
       "      <td>53%</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>11%</td>\n",
       "      <td>606</td>\n",
       "      <td>595</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>100%</td>\n",
       "      <td>530</td>\n",
       "      <td>512</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>100%</td>\n",
       "      <td>503</td>\n",
       "      <td>492</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>100%</td>\n",
       "      <td>482</td>\n",
       "      <td>468</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Florida</td>\n",
       "      <td>83%</td>\n",
       "      <td>520</td>\n",
       "      <td>497</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 State Participation  \\\n",
       "0           0               Alabama            5%   \n",
       "1           1                Alaska           38%   \n",
       "2           2               Arizona           30%   \n",
       "3           3              Arkansas            3%   \n",
       "4           4            California           53%   \n",
       "5           5              Colorado           11%   \n",
       "6           6           Connecticut          100%   \n",
       "7           7              Delaware          100%   \n",
       "8           8  District of Columbia          100%   \n",
       "9           9               Florida           83%   \n",
       "\n",
       "   Evidence-Based Reading and Writing  Math  Total  \n",
       "0                                 593   572   1165  \n",
       "1                                 547   533   1080  \n",
       "2                                 563   553   1116  \n",
       "3                                 614   594   1208  \n",
       "4                                 531   524   1055  \n",
       "5                                 606   595   1201  \n",
       "6                                 530   512   1041  \n",
       "7                                 503   492    996  \n",
       "8                                 482   468    950  \n",
       "9                                 520   497   1017  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Describe in words what each variable (column) is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSAT CSV Column Headers\\nUnnamed: Index of state\\nState: The states where data was collected\\nParticipation: The percentages of how many students particpated in the SAT Exams\\nEvidence-Based Reading and Writing: Mean scores for the \"Evidence-Based Reading and Writing\" portion of the SATs\\nMath: Mean scores for the \"Math\" portion of the SATs\\nTotal: The sum of the \"Evidence-Based Reading and Writing\" and \"Math\" mean scores\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ACT CSV Column Headers\n",
    "Unnamed: Index of state\n",
    "State: The states where data was collected\n",
    "Participation: The percentages of how many students particpated in the SAT Exams\n",
    "English: Mean scores for the \"English\" portion of the SATs\n",
    "Math: Mean scores for the \"Math\" portion of the SATs\n",
    "Reading: Mean scores for the \"Reading\" portion of the SATs\n",
    "Science: Mean scores for the \"Science\" portion of the SATs\n",
    "Composite: Mean scores of all of the tests\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SAT CSV Column Headers\n",
    "Unnamed: Index of state\n",
    "State: The states where data was collected\n",
    "Participation: The percentages of how many students particpated in the SAT Exams\n",
    "Evidence-Based Reading and Writing: Mean scores for the \"Evidence-Based Reading and Writing\" portion of the SATs\n",
    "Math: Mean scores for the \"Math\" portion of the SATs\n",
    "Total: The sum of the \"Evidence-Based Reading and Writing\" and \"Math\" mean scores\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Does the data look complete? Are there any obvious issues with the observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Print the types of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                              int64\n",
       "State                                  object\n",
       "Participation                         float64\n",
       "Evidence-Based Reading and Writing      int64\n",
       "Math                                    int64\n",
       "Total                                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         int64\n",
       "State             object\n",
       "Participation    float64\n",
       "English          float64\n",
       "Math             float64\n",
       "Reading          float64\n",
       "Science          float64\n",
       "Composite        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Do any types need to be reassigned? If so, go ahead and do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Participation</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.874326</td>\n",
       "      <td>-0.566558</td>\n",
       "      <td>-0.867540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <td>-0.874326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.628405</td>\n",
       "      <td>0.996661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Math</th>\n",
       "      <td>-0.566558</td>\n",
       "      <td>0.628405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>-0.867540</td>\n",
       "      <td>0.996661</td>\n",
       "      <td>0.632648</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Participation  \\\n",
       "Participation                            1.000000   \n",
       "Evidence-Based Reading and Writing      -0.874326   \n",
       "Math                                    -0.566558   \n",
       "Total                                   -0.867540   \n",
       "\n",
       "                                    Evidence-Based Reading and Writing  \\\n",
       "Participation                                                -0.874326   \n",
       "Evidence-Based Reading and Writing                            1.000000   \n",
       "Math                                                          0.628405   \n",
       "Total                                                         0.996661   \n",
       "\n",
       "                                        Math     Total  \n",
       "Participation                      -0.566558 -0.867540  \n",
       "Evidence-Based Reading and Writing  0.628405  0.996661  \n",
       "Math                                1.000000  0.632648  \n",
       "Total                               0.632648  1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def percentage_to_num(row):\n",
    "    if type(row['Participation'])== str:\n",
    "        return int(row['Participation'].replace(\"%\",\"\"))/100\n",
    "    else:\n",
    "        return row['Participation']\n",
    "\n",
    "sat_data['Participation'] = sat_data.apply(lambda row: percentage_to_num(row), axis=1)\n",
    "sat_data.iloc[:,1:6].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Participation</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.841826</td>\n",
       "      <td>-0.859609</td>\n",
       "      <td>-0.864694</td>\n",
       "      <td>-0.304870</td>\n",
       "      <td>-0.856530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>-0.841826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967838</td>\n",
       "      <td>0.986012</td>\n",
       "      <td>0.403239</td>\n",
       "      <td>0.990867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Math</th>\n",
       "      <td>-0.859609</td>\n",
       "      <td>0.967838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979632</td>\n",
       "      <td>0.412140</td>\n",
       "      <td>0.990461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading</th>\n",
       "      <td>-0.864694</td>\n",
       "      <td>0.986012</td>\n",
       "      <td>0.979632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.995061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science</th>\n",
       "      <td>-0.304870</td>\n",
       "      <td>0.403239</td>\n",
       "      <td>0.412140</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Composite</th>\n",
       "      <td>-0.856530</td>\n",
       "      <td>0.990867</td>\n",
       "      <td>0.990461</td>\n",
       "      <td>0.995061</td>\n",
       "      <td>0.408455</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Participation   English      Math   Reading   Science  \\\n",
       "Participation       1.000000 -0.841826 -0.859609 -0.864694 -0.304870   \n",
       "English            -0.841826  1.000000  0.967838  0.986012  0.403239   \n",
       "Math               -0.859609  0.967838  1.000000  0.979632  0.412140   \n",
       "Reading            -0.864694  0.986012  0.979632  1.000000  0.400826   \n",
       "Science            -0.304870  0.403239  0.412140  0.400826  1.000000   \n",
       "Composite          -0.856530  0.990867  0.990461  0.995061  0.408455   \n",
       "\n",
       "               Composite  \n",
       "Participation  -0.856530  \n",
       "English         0.990867  \n",
       "Math            0.990461  \n",
       "Reading         0.995061  \n",
       "Science         0.408455  \n",
       "Composite       1.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_data['Participation'] = act_data.apply(lambda row: percentage_to_num(row), axis=1)\n",
    "act_data.iloc[:,1:8].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Create a dictionary for each column mapping the State to its respective value for that column. (For example, you should have three SAT dictionaries.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Evidence-Based Reading and Writing': {'Alabama': 593,\n",
       "  'Alaska': 547,\n",
       "  'Arizona': 563,\n",
       "  'Arkansas': 614,\n",
       "  'California': 531,\n",
       "  'Colorado': 606,\n",
       "  'Connecticut': 530,\n",
       "  'Delaware': 503,\n",
       "  'District of Columbia': 482,\n",
       "  'Florida': 520,\n",
       "  'Georgia': 535,\n",
       "  'Hawaii': 544,\n",
       "  'Idaho': 513,\n",
       "  'Illinois': 559,\n",
       "  'Indiana': 542,\n",
       "  'Iowa': 641,\n",
       "  'Kansas': 632,\n",
       "  'Kentucky': 631,\n",
       "  'Louisiana': 611,\n",
       "  'Maine': 513,\n",
       "  'Maryland': 536,\n",
       "  'Massachusetts': 555,\n",
       "  'Michigan': 509,\n",
       "  'Minnesota': 644,\n",
       "  'Mississippi': 634,\n",
       "  'Missouri': 640,\n",
       "  'Montana': 605,\n",
       "  'Nebraska': 629,\n",
       "  'Nevada': 563,\n",
       "  'New Hampshire': 532,\n",
       "  'New Jersey': 530,\n",
       "  'New Mexico': 577,\n",
       "  'New York': 528,\n",
       "  'North Carolina': 546,\n",
       "  'North Dakota': 635,\n",
       "  'Ohio': 578,\n",
       "  'Oklahoma': 530,\n",
       "  'Oregon': 560,\n",
       "  'Pennsylvania': 540,\n",
       "  'Rhode Island': 539,\n",
       "  'South Carolina': 543,\n",
       "  'South Dakota': 612,\n",
       "  'Tennessee': 623,\n",
       "  'Texas': 513,\n",
       "  'Utah': 624,\n",
       "  'Vermont': 562,\n",
       "  'Virginia': 561,\n",
       "  'Washington': 541,\n",
       "  'West Virginia': 558,\n",
       "  'Wisconsin': 642,\n",
       "  'Wyoming': 626},\n",
       " 'Math': {'Alabama': 572,\n",
       "  'Alaska': 533,\n",
       "  'Arizona': 553,\n",
       "  'Arkansas': 594,\n",
       "  'California': 524,\n",
       "  'Colorado': 595,\n",
       "  'Connecticut': 512,\n",
       "  'Delaware': 492,\n",
       "  'District of Columbia': 468,\n",
       "  'Florida': 497,\n",
       "  'Georgia': 515,\n",
       "  'Hawaii': 541,\n",
       "  'Idaho': 493,\n",
       "  'Illinois': 556,\n",
       "  'Indiana': 532,\n",
       "  'Iowa': 635,\n",
       "  'Kansas': 628,\n",
       "  'Kentucky': 616,\n",
       "  'Louisiana': 586,\n",
       "  'Maine': 499,\n",
       "  'Maryland': 52,\n",
       "  'Massachusetts': 551,\n",
       "  'Michigan': 495,\n",
       "  'Minnesota': 651,\n",
       "  'Mississippi': 607,\n",
       "  'Missouri': 631,\n",
       "  'Montana': 591,\n",
       "  'Nebraska': 625,\n",
       "  'Nevada': 553,\n",
       "  'New Hampshire': 520,\n",
       "  'New Jersey': 526,\n",
       "  'New Mexico': 561,\n",
       "  'New York': 523,\n",
       "  'North Carolina': 535,\n",
       "  'North Dakota': 621,\n",
       "  'Ohio': 570,\n",
       "  'Oklahoma': 517,\n",
       "  'Oregon': 548,\n",
       "  'Pennsylvania': 531,\n",
       "  'Rhode Island': 524,\n",
       "  'South Carolina': 521,\n",
       "  'South Dakota': 603,\n",
       "  'Tennessee': 604,\n",
       "  'Texas': 507,\n",
       "  'Utah': 614,\n",
       "  'Vermont': 551,\n",
       "  'Virginia': 541,\n",
       "  'Washington': 534,\n",
       "  'West Virginia': 528,\n",
       "  'Wisconsin': 649,\n",
       "  'Wyoming': 604},\n",
       " 'Total': {'Alabama': 1165,\n",
       "  'Alaska': 1080,\n",
       "  'Arizona': 1116,\n",
       "  'Arkansas': 1208,\n",
       "  'California': 1055,\n",
       "  'Colorado': 1201,\n",
       "  'Connecticut': 1041,\n",
       "  'Delaware': 996,\n",
       "  'District of Columbia': 950,\n",
       "  'Florida': 1017,\n",
       "  'Georgia': 1050,\n",
       "  'Hawaii': 1085,\n",
       "  'Idaho': 1005,\n",
       "  'Illinois': 1115,\n",
       "  'Indiana': 1074,\n",
       "  'Iowa': 1275,\n",
       "  'Kansas': 1260,\n",
       "  'Kentucky': 1247,\n",
       "  'Louisiana': 1198,\n",
       "  'Maine': 1012,\n",
       "  'Maryland': 1060,\n",
       "  'Massachusetts': 1107,\n",
       "  'Michigan': 1005,\n",
       "  'Minnesota': 1295,\n",
       "  'Mississippi': 1242,\n",
       "  'Missouri': 1271,\n",
       "  'Montana': 1196,\n",
       "  'Nebraska': 1253,\n",
       "  'Nevada': 1116,\n",
       "  'New Hampshire': 1052,\n",
       "  'New Jersey': 1056,\n",
       "  'New Mexico': 1138,\n",
       "  'New York': 1052,\n",
       "  'North Carolina': 1081,\n",
       "  'North Dakota': 1256,\n",
       "  'Ohio': 1149,\n",
       "  'Oklahoma': 1047,\n",
       "  'Oregon': 1108,\n",
       "  'Pennsylvania': 1071,\n",
       "  'Rhode Island': 1062,\n",
       "  'South Carolina': 1064,\n",
       "  'South Dakota': 1216,\n",
       "  'Tennessee': 1228,\n",
       "  'Texas': 1020,\n",
       "  'Utah': 1238,\n",
       "  'Vermont': 1114,\n",
       "  'Virginia': 1102,\n",
       "  'Washington': 1075,\n",
       "  'West Virginia': 1086,\n",
       "  'Wisconsin': 1291,\n",
       "  'Wyoming': 1230}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_header_state_list = {}\n",
    "\n",
    "for column_header in ['Evidence-Based Reading and Writing','Math','Total']:\n",
    "    temp_dict = {}\n",
    "    for idx, val in enumerate(sat_data[column_header]):\n",
    "        temp_dict[sat_data[\"State\"][idx]] = val\n",
    "    sat_header_state_list[column_header] = temp_dict\n",
    "\n",
    "sat_header_state_list\n",
    "\n",
    "# Do the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Create one dictionary where each key is the column name, and each value is an iterable (a list or a Pandas Series) of all the values in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Merge the dataframes on the state column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. Change the names of the columns so you can distinguish between the SAT columns and the ACT columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Print the minimum and maximum of each numeric column in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Write a function using only list comprehensions, no loops, to compute standard deviation. Using this function, calculate the standard deviation of each numeric column in both data sets. Add these to a list called `sd`.\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Manipulate the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 13. Turn the list `sd` into a new observation in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Sort the dataframe by the values in a numeric column (e.g. observations descending by SAT participation rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Use a boolean filter to display only observations with a score above a certain threshold (e.g. only states with a participation rate above 50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 16. Using MatPlotLib and PyPlot, plot the distribution of the Rate columns for both SAT and ACT using histograms. (You should have two histograms. You might find [this link](https://matplotlib.org/users/pyplot_tutorial.html#working-with-multiple-figures-and-axes) helpful in organizing one plot above the other.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 17. Plot the Math(s) distributions from both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. Plot the Verbal distributions from both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. When we make assumptions about how data are distributed, what is the most common assumption?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20. Does this assumption hold true for any of our columns? Which?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. Plot some scatterplots examining relationships between all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Are there any interesting relationships to note?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Create box plots for each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BONUS: Using Tableau, create a heat map for each variable using a map of the US. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Descriptive and Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Summarize each distribution. As data scientists, be sure to back up these summaries with statistics. (Hint: What are the three things we care about when describing distributions?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Summarize each relationship. Be sure to back up these summaries with statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Execute a hypothesis test comparing the SAT and ACT participation rates. Use $\\alpha = 0.05$. Be sure to interpret your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Generate and interpret 95% confidence intervals for SAT and ACT participation rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 28. Given your answer to 26, was your answer to 27 surprising? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 29. Is it appropriate to generate correlation between SAT and ACT math scores? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 30. Suppose we only seek to understand the relationship between SAT and ACT data in 2017. Does it make sense to conduct statistical inference given the data we have? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
