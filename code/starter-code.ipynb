{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data and perform basic operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Load the data in using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "act_data = pd.read_csv(\"../data/act.csv\")\n",
    "sat_data = pd.read_csv(\"../data/sat.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Print the first ten rows of each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>National</td>\n",
       "      <td>60%</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>65%</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>62%</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>California</td>\n",
       "      <td>31%</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>100%</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>31%</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>18%</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>32%</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 State Participation  English  Math  Reading  \\\n",
       "0           0              National           60%     20.3  20.7     21.4   \n",
       "1           1               Alabama          100%     18.9  18.4     19.7   \n",
       "2           2                Alaska           65%     18.7  19.8     20.4   \n",
       "3           3               Arizona           62%     18.6  19.8     20.1   \n",
       "4           4              Arkansas          100%     18.9  19.0     19.7   \n",
       "5           5            California           31%     22.5  22.7     23.1   \n",
       "6           6              Colorado          100%     20.1  20.3     21.2   \n",
       "7           7           Connecticut           31%     25.5  24.6     25.6   \n",
       "8           8              Delaware           18%     24.1  23.4     24.8   \n",
       "9           9  District of Columbia           32%     24.4  23.5     24.9   \n",
       "\n",
       "   Science  Composite  \n",
       "0     21.0       21.0  \n",
       "1     19.4       19.2  \n",
       "2     19.9       19.8  \n",
       "3     19.8       19.7  \n",
       "4     19.5       19.4  \n",
       "5     22.2       22.8  \n",
       "6     20.9       20.8  \n",
       "7     24.6       25.2  \n",
       "8     23.6       24.1  \n",
       "9     23.5       24.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>5%</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>38%</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>30%</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3%</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>California</td>\n",
       "      <td>53%</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>11%</td>\n",
       "      <td>606</td>\n",
       "      <td>595</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>100%</td>\n",
       "      <td>530</td>\n",
       "      <td>512</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>100%</td>\n",
       "      <td>503</td>\n",
       "      <td>492</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>100%</td>\n",
       "      <td>482</td>\n",
       "      <td>468</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Florida</td>\n",
       "      <td>83%</td>\n",
       "      <td>520</td>\n",
       "      <td>497</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 State Participation  \\\n",
       "0           0               Alabama            5%   \n",
       "1           1                Alaska           38%   \n",
       "2           2               Arizona           30%   \n",
       "3           3              Arkansas            3%   \n",
       "4           4            California           53%   \n",
       "5           5              Colorado           11%   \n",
       "6           6           Connecticut          100%   \n",
       "7           7              Delaware          100%   \n",
       "8           8  District of Columbia          100%   \n",
       "9           9               Florida           83%   \n",
       "\n",
       "   Evidence-Based Reading and Writing  Math  Total  \n",
       "0                                 593   572   1165  \n",
       "1                                 547   533   1080  \n",
       "2                                 563   553   1116  \n",
       "3                                 614   594   1208  \n",
       "4                                 531   524   1055  \n",
       "5                                 606   595   1201  \n",
       "6                                 530   512   1041  \n",
       "7                                 503   492    996  \n",
       "8                                 482   468    950  \n",
       "9                                 520   497   1017  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Describe in words what each variable (column) is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACT CSV Column Headers\n",
    "__Unnamed__: Index of state\n",
    "\n",
    "__State__: The states where data was collected\n",
    "\n",
    "__Participation__: The percentages of how many students particpated in the SAT Exams\n",
    "\n",
    "__English__: Mean scores for the \"English\" portion of the SATs\n",
    "\n",
    "__Math__: Mean scores for the \"Math\" portion of the SATs\n",
    "\n",
    "__Reading__: Mean scores for the \"Reading\" portion of the SATs\n",
    "\n",
    "__Science__: Mean scores for the \"Science\" portion of the SATs\n",
    "\n",
    "__Composite__: Mean scores of all of the tests\n",
    "\n",
    "\n",
    "## SAT CSV Column Headers\n",
    "\n",
    "__Unnamed__: Index of state\n",
    "\n",
    "__State__: The states where data was collected\n",
    "\n",
    "__Participation__: The percentages of how many students particpated in the SAT Exams\n",
    "\n",
    "__Evidence-Based Reading and Writing__: Mean scores for the \"Evidence-Based Reading and Writing\" portion of the SATs\n",
    "\n",
    "__Math__: Mean scores for the \"Math\" portion of the SATs\n",
    "\n",
    "__Total__: The sum of the \"Evidence-Based Reading and Writing\" and \"Math\" mean scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Does the data look complete? Are there any obvious issues with the observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Print the types of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                             int64\n",
       "State                                 object\n",
       "Participation                         object\n",
       "Evidence-Based Reading and Writing     int64\n",
       "Math                                   int64\n",
       "Total                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         int64\n",
       "State             object\n",
       "Participation     object\n",
       "English          float64\n",
       "Math             float64\n",
       "Reading          float64\n",
       "Science          float64\n",
       "Composite        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Do any types need to be reassigned? If so, go ahead and do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_to_num(row):\n",
    "    if type(row['Participation'])== str:\n",
    "        return int(row['Participation'].replace(\"%\",\"\"))/100\n",
    "    else:\n",
    "        return row['Participation']\n",
    "\n",
    "sat_data['Participation'] = sat_data.apply(lambda row: percentage_to_num(row), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data['Participation'] = act_data.apply(lambda row: percentage_to_num(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Create a dictionary for each column mapping the State to its respective value for that column. (For example, you should have three SAT dictionaries.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_column(data,column):    \n",
    "    temp_dict = {}\n",
    "    for idx, val in enumerate(data[column]):\n",
    "        temp_dict[data[\"State\"][idx]] = val\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAT Data\n",
    "sat_ebrw_dict = map_to_column(sat_data,'Evidence-Based Reading and Writing')\n",
    "sat_math_dict = map_to_column(sat_data,'Math')\n",
    "sat_total_dict = map_to_column(sat_data,'Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACT Data\n",
    "act_english_dict = map_to_column(act_data,\"English\")\n",
    "act_math_dict = map_to_column(act_data,\"Math\")\n",
    "act_reading_dict = map_to_column(act_data,\"Reading\")\n",
    "act_science_dict = map_to_column(act_data,\"Science\")\n",
    "act_composite_dict = map_to_column(act_data,\"Composite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Create one dictionary where each key is the column name, and each value is an iterable (a list or a Pandas Series) of all the values in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_header_state_list = {}\n",
    "for column_header in ['Evidence-Based Reading and Writing','Math','Total']:\n",
    "    temp_dict = {}\n",
    "    for idx, val in enumerate(sat_data[column_header]):\n",
    "        temp_dict[sat_data[\"State\"][idx]] = val\n",
    "    sat_header_state_list[column_header] = temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_header_state_list = {}\n",
    "for column_header in [\"English\",\"Math\",\"Reading\",\"Science\",\"Composite\"]:\n",
    "    temp_dict = {}\n",
    "    for idx, val in enumerate(act_data[column_header]):\n",
    "        temp_dict[act_data[\"State\"][idx]] = val\n",
    "    act_header_state_list[column_header] = temp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Merge the dataframes on the state column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    act_data.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "    sat_data.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "merged_test_data = pd.merge(act_data, sat_data, how='inner', on=\"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation_x</th>\n",
       "      <th>English</th>\n",
       "      <th>Math_x</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "      <th>Participation_y</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math_y</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.31</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Participation_x  English  Math_x  Reading  Science  Composite  \\\n",
       "0     Alabama             1.00     18.9    18.4     19.7     19.4       19.2   \n",
       "1      Alaska             0.65     18.7    19.8     20.4     19.9       19.8   \n",
       "2     Arizona             0.62     18.6    19.8     20.1     19.8       19.7   \n",
       "3    Arkansas             1.00     18.9    19.0     19.7     19.5       19.4   \n",
       "4  California             0.31     22.5    22.7     23.1     22.2       22.8   \n",
       "\n",
       "   Participation_y  Evidence-Based Reading and Writing  Math_y  Total  \n",
       "0             0.05                                 593     572   1165  \n",
       "1             0.38                                 547     533   1080  \n",
       "2             0.30                                 563     553   1116  \n",
       "3             0.03                                 614     594   1208  \n",
       "4             0.53                                 531     524   1055  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. Change the names of the columns so you can distinguish between the SAT columns and the ACT columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act_participation</th>\n",
       "      <th>act_english</th>\n",
       "      <th>act_math</th>\n",
       "      <th>act_reading</th>\n",
       "      <th>act_science</th>\n",
       "      <th>act_composite</th>\n",
       "      <th>sat_participation</th>\n",
       "      <th>sat_evidence_based_reading_and_writing</th>\n",
       "      <th>sat_math</th>\n",
       "      <th>sat_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.31</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  act_participation  act_english  act_math  act_reading  \\\n",
       "0     Alabama               1.00         18.9      18.4         19.7   \n",
       "1      Alaska               0.65         18.7      19.8         20.4   \n",
       "2     Arizona               0.62         18.6      19.8         20.1   \n",
       "3    Arkansas               1.00         18.9      19.0         19.7   \n",
       "4  California               0.31         22.5      22.7         23.1   \n",
       "\n",
       "   act_science  act_composite  sat_participation  \\\n",
       "0         19.4           19.2               0.05   \n",
       "1         19.9           19.8               0.38   \n",
       "2         19.8           19.7               0.30   \n",
       "3         19.5           19.4               0.03   \n",
       "4         22.2           22.8               0.53   \n",
       "\n",
       "   sat_evidence_based_reading_and_writing  sat_math  sat_total  \n",
       "0                                     593       572       1165  \n",
       "1                                     547       533       1080  \n",
       "2                                     563       553       1116  \n",
       "3                                     614       594       1208  \n",
       "4                                     531       524       1055  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modify_column_name(column_name):\n",
    "    if column_name.find(\"_x\") > -1 or column_name in [\"Reading\",\"Science\",\"English\",\"Composite\"]:\n",
    "        return f'act_{column_name.replace(\"_x\",\"\").lower()}'\n",
    "    elif column_name.find(\"_y\") > -1 or column_name in [\"Evidence-Based Reading and Writing\",\"Total\"]:\n",
    "        return f'sat_{column_name.replace(\"_y\",\"\").replace(\" \",\"_\").replace(\"-\",\"_\").lower()}'\n",
    "    else:\n",
    "        return column_name.lower()\n",
    "\n",
    "new_columns_dict = {column: modify_column_name(column) for column in merged_test_data.columns}\n",
    "merged_test_data.rename(index=str, columns=new_columns_dict, inplace=True)\n",
    "merged_test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Print the minimum and maximum of each numeric column in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value for act_participation: 0.08\n",
      "Min value for act_participation: 1.0\n",
      "\n",
      "Min value for act_english: 16.3\n",
      "Min value for act_english: 25.5\n",
      "\n",
      "Min value for act_math: 18.0\n",
      "Min value for act_math: 25.3\n",
      "\n",
      "Min value for act_reading: 18.1\n",
      "Min value for act_reading: 26.0\n",
      "\n",
      "Min value for act_science: 2.3\n",
      "Min value for act_science: 24.9\n",
      "\n",
      "Min value for act_composite: 17.8\n",
      "Min value for act_composite: 25.5\n",
      "\n",
      "Min value for sat_participation: 0.02\n",
      "Min value for sat_participation: 1.0\n",
      "\n",
      "Min value for sat_evidence_based_reading_and_writing: 482\n",
      "Min value for sat_evidence_based_reading_and_writing: 644\n",
      "\n",
      "Min value for sat_math: 52\n",
      "Min value for sat_math: 651\n",
      "\n",
      "Min value for sat_total: 950\n",
      "Min value for sat_total: 1295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in merged_test_data.columns:\n",
    "    if merged_test_data[column].dtypes != object:\n",
    "        print(f\"Min value for {column}: {merged_test_data[column].min()}\")\n",
    "        print(f\"Min value for {column}: {merged_test_data[column].max()}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Write a function using only list comprehensions, no loops, to compute standard deviation. Using this function, calculate the standard deviation of each numeric column in both data sets. Add these to a list called `sd`.\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Participation': 0.35276632270013036, 'Evidence-Based Reading and Writing': 45.66690138768932, 'Math': 84.90911865855486, 'Total': 92.49481172519046}\n",
      "\n",
      "{'Participation': 0.3183251797460136, 'English': 2.332131774228897, 'Math': 1.9636016712608966, 'Reading': 2.048671533650611, 'Science': 3.151113069164709, 'Composite': 2.002083191096813}\n",
      "\n",
      "{'act_participation': 0.3215377875950477, 'act_english': 3.4739462798233136, 'act_math': 3.3076814194471695, 'act_reading': 3.441073360600396, 'act_science': 4.0078448507812965, 'act_composite': 3.3637523215843173, 'sat_participation': 0.34934712610343954, 'sat_evidence_based_reading_and_writing': 85.52086471190897, 'sat_math': 105.76228526347069, 'sat_total': 170.09543029014236}\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "## I ported this from some javascript that I put together from the prework...\n",
    "# https://gist.git.generalassemb.ly/rajandavis/67d2a1c150eb931ed8cf6d0c1f4b5a42\n",
    "\n",
    "## 1. find the mean\n",
    "def get_mean(arr):\n",
    "    return sum(arr) / len(arr)\n",
    "\n",
    "## 2. get differences of values and mean\n",
    "def mean_diff(arr):\n",
    "    return list(map(lambda x:  x - get_mean(arr), arr))\n",
    "\n",
    "## 3. square the results\n",
    "def squared_mean_diff(arr):\n",
    "    return list(map(lambda x:  x ** 2, mean_diff(arr)))\n",
    "\n",
    "## 4. sum the squared results\n",
    "def sum_of_squared_mean_diff(arr):\n",
    "    return sum(squared_mean_diff(arr))\n",
    "\n",
    "## 5. divide the summed results by (length of array - 1) => variance\n",
    "def get_variance(arr):\n",
    "    return (sum_of_squared_mean_diff(arr) / (len(arr) - 1))\n",
    "\n",
    "## 6. square root the variance to get the standard deviation\n",
    "def get_standard_deviation(arr):\n",
    "    return math.sqrt(get_variance(arr))\n",
    "\n",
    "## Get all of the numeric columns for a data set\n",
    "def get_numeric_columns(data_arr):\n",
    "    return [column for column in data_arr.columns.where(data_arr.dtypes != object).dropna()]\n",
    "\n",
    "## Create a dictionary of columns and their standard deviations\n",
    "def std_dev_by_column(data_arr):\n",
    "    numeric_columns = get_numeric_columns(data_arr)\n",
    "    return {column: get_standard_deviation(data_arr[column]) for column in  numeric_columns}\n",
    "\n",
    "# Get the standard deviations for each column\n",
    "merged_data_std_dev_by_column = std_dev_by_column(merged_test_data)\n",
    "sat_std_dev_by_column = std_dev_by_column(sat_data)\n",
    "\n",
    "# Slightly different than the merged_data\n",
    "# because there is a \"National\" value\n",
    "act_std_dev_by_column = std_dev_by_column(act_data)\n",
    "\n",
    "print(sat_std_dev_by_column)\n",
    "print()\n",
    "print(act_std_dev_by_column)\n",
    "print()\n",
    "print(merged_data_std_dev_by_column)\n",
    "\n",
    "# get the values\n",
    "sd = [value for key,value in merged_data_std_dev_by_column.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Manipulate the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 13. Turn the list `sd` into a new observation in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only modify once\n",
    "if len(sd) == 10:\n",
    "    sd = [\"\"] + sd\n",
    "\n",
    "merged_test_data.loc['std'] = sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Sort the dataframe by the values in a numeric column (e.g. observations descending by SAT participation rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act_participation</th>\n",
       "      <th>act_english</th>\n",
       "      <th>act_math</th>\n",
       "      <th>act_reading</th>\n",
       "      <th>act_science</th>\n",
       "      <th>act_composite</th>\n",
       "      <th>sat_participation</th>\n",
       "      <th>sat_evidence_based_reading_and_writing</th>\n",
       "      <th>sat_math</th>\n",
       "      <th>sat_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>644.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>1295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.11</td>\n",
       "      <td>606.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>1201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>640.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>1271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>642.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>1291.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>631.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>1247.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  act_participation  act_english  act_math  act_reading  \\\n",
       "23  Minnesota                1.0         20.4      21.5         21.8   \n",
       "5    Colorado                1.0         20.1      20.3         21.2   \n",
       "25   Missouri                1.0         19.8      19.9         20.8   \n",
       "49  Wisconsin                1.0         19.7      20.4         20.6   \n",
       "17   Kentucky                1.0         19.6      19.4         20.5   \n",
       "\n",
       "    act_science  act_composite  sat_participation  \\\n",
       "23         21.6           21.5               0.03   \n",
       "5          20.9           20.8               0.11   \n",
       "25         20.5           20.4               0.03   \n",
       "49         20.9           20.5               0.03   \n",
       "17         20.1           20.0               0.04   \n",
       "\n",
       "    sat_evidence_based_reading_and_writing  sat_math  sat_total  \n",
       "23                                   644.0     651.0     1295.0  \n",
       "5                                    606.0     595.0     1201.0  \n",
       "25                                   640.0     631.0     1271.0  \n",
       "49                                   642.0     649.0     1291.0  \n",
       "17                                   631.0     616.0     1247.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_test_data.sort_values(by=get_numeric_columns(merged_test_data), ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Use a boolean filter to display only observations with a score above a certain threshold (e.g. only states with a participation rate above 50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act_participation</th>\n",
       "      <th>act_english</th>\n",
       "      <th>act_math</th>\n",
       "      <th>act_reading</th>\n",
       "      <th>act_science</th>\n",
       "      <th>act_composite</th>\n",
       "      <th>sat_participation</th>\n",
       "      <th>sat_evidence_based_reading_and_writing</th>\n",
       "      <th>sat_math</th>\n",
       "      <th>sat_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.31</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.53</td>\n",
       "      <td>531.0</td>\n",
       "      <td>524.0</td>\n",
       "      <td>1055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>0.31</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>530.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1041.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>0.18</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>503.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>0.32</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>482.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>0.73</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.83</td>\n",
       "      <td>520.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>1017.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  state  act_participation  act_english  act_math  \\\n",
       "4            California               0.31         22.5      22.7   \n",
       "6           Connecticut               0.31         25.5      24.6   \n",
       "7              Delaware               0.18         24.1      23.4   \n",
       "8  District of Columbia               0.32         24.4      23.5   \n",
       "9               Florida               0.73         19.0      19.4   \n",
       "\n",
       "   act_reading  act_science  act_composite  sat_participation  \\\n",
       "4         23.1         22.2           22.8               0.53   \n",
       "6         25.6         24.6           25.2               1.00   \n",
       "7         24.8         23.6           24.1               1.00   \n",
       "8         24.9         23.5           24.2               1.00   \n",
       "9         21.0         19.4           19.8               0.83   \n",
       "\n",
       "   sat_evidence_based_reading_and_writing  sat_math  sat_total  \n",
       "4                                   531.0     524.0     1055.0  \n",
       "6                                   530.0     512.0     1041.0  \n",
       "7                                   503.0     492.0      996.0  \n",
       "8                                   482.0     468.0      950.0  \n",
       "9                                   520.0     497.0     1017.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_test_data.loc[merged_test_data[\"sat_participation\"] > .5].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 16. Using MatPlotLib and PyPlot, plot the distribution of the Rate columns for both SAT and ACT using histograms. (You should have two histograms. You might find [this link](https://matplotlib.org/users/pyplot_tutorial.html#working-with-multiple-figures-and-axes) helpful in organizing one plot above the other.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 17. Plot the Math(s) distributions from both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. Plot the Verbal distributions from both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. When we make assumptions about how data are distributed, what is the most common assumption?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20. Does this assumption hold true for any of our columns? Which?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. Plot some scatterplots examining relationships between all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Are there any interesting relationships to note?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Create box plots for each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BONUS: Using Tableau, create a heat map for each variable using a map of the US. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Descriptive and Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Summarize each distribution. As data scientists, be sure to back up these summaries with statistics. (Hint: What are the three things we care about when describing distributions?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Summarize each relationship. Be sure to back up these summaries with statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Execute a hypothesis test comparing the SAT and ACT participation rates. Use $\\alpha = 0.05$. Be sure to interpret your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Generate and interpret 95% confidence intervals for SAT and ACT participation rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 28. Given your answer to 26, was your answer to 27 surprising? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 29. Is it appropriate to generate correlation between SAT and ACT math scores? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 30. Suppose we only seek to understand the relationship between SAT and ACT data in 2017. Does it make sense to conduct statistical inference given the data we have? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
